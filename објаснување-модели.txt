Cross Validation(крос-валидација)
Оваа техника се користи за избегнување на overfitting кај повеќе модели(пр. линеарна регресија,
логистичка регресија, КНН итн. Но, исто така и за проценка на перфомрансите на моделите.
Функционира на начин што првен се дели дата сетот на к подмножества(folds).
Моделот се тренира к-1 пати , секогаш се користи различен сет за тестирање, се прават
к итерации каде во секоја итерација секој fold барем еднаш ја има улогата на test сет.
На крај на секоја итерација се пресметува средна вредност од секој fold.
---------------------------------------------------------------------------------------------------------
R^2 -> R squared 
R^2 претставува коефициент на детерминација или квадратна грешка која помага во тоа да ги увидиме
перформансите на еден модел, вообичаено се користи кај регресиски модели(модел на линеарна регресија)
Покажува колку добро моделот ја објаснува зависната променливс Y (која ја предвидуваме) врз основа на
независните променливи X. Доколку вредноста нејзина е 0, ова значи моделот не е воопшто добар, односно
независните променливи не даваат никакви информации за променливата што ја предивудаме, но доколку
нејзината вредност е 1 , значи моделот е добар и дека целосно ја објаснува варијансата во зависната променлива.
-------------------------------------------------------------------------------------------------------------------
Класификација 
Линеарната регрсија добро функционира доколку променливата што ја предвиудаваме е од нумерички тип, но кога
променливите кои ги предвидуваме се од категориски тип, проблемот не е повеќе регресивен проблем , туку проблем на
класификација. Целта наша е да се обидеме да ја класифицираме променливата Y позната како класа/кластер врз основа
на множество од променливи на предивудање X. Класификацијата може да биде бинарна класификација пример доколку
предвидуваме дали личноста е машко или женско, дали ќе добие кредит или не итн. мултилабел класификација каде имаме 
повеќе од 2 вредности на излез.
-----------------------------------------------------------------------------------------------------------------
Важни мерки за перформанси на модели (Accuracy, Precision, F1-Score, Recall)
1)Precision - пример предвидуваме јаболка и круши -> колку од сите јаболка што сме ги предвиделе како јаболка 
се навистина јаболка ; 
Ex. ако предвидиме 10 јаболка, а само 7 се навистина јаболка тогаш прецизноста е :
  	[ TP / TP + FP] <=> [ 7 / 7 + 3 ] => 0.7 ( 70%)
2) Recall(отповик) - пример предвидуваме јаболка и круши -> колку од вкупното овошје успеал моделот да лабелира
примероци како јаболка
Ex. ако имаме 7 јаболка, а моделот открил правилно 5 од нив тогаш :
 	[ TP / TP + FN ] <=> [5 / 5 + 2 ] => 0.71 ( 71%)
3) Accuracy(точност) - покажува колкав процент од сите предвидување ( позитивни и негативни) на моделот се точни.
	[TP + TN / all samples]
4) F1-score - е баланс помеѓу precision и recall(од него можеме да видиме дали еден dataset е балансиран/не)
-----------------------------------------------------------------------------------------------------------------
	Што е стандардизација, што е нормализација?

-Стандардизација е процес на скалирање на податоците така што тие ќе имаат средна вредност(просек) = 0 и
стандардна девијација = 1. Стандардизација вршиме за да ги направиме карактеристиките (features) споредливи
доколку имаат различни параметри или единици. Се користи особено кај алгоритми како КNN, логистичка регресија итн.
-Нормализација е процес на скалирање на податоците така што сите вредности ќе бидат во опсег од 0 до 1. Ова го правиме
со цел да се осигураме дека карактеристиките се во ист опсег.
-Ова го правиме бидејќи многу алгоритми во машинското учење учат подобро и работат подобро и побрзо кога карактеристиките 
се слични и исто така го подобруваме перформансот и точноста на моделите.
---------------------------------------------------------------------------------------------------------------------
	Зошто balanced DataSet Accuracy не е корисна?(BDA) 

Не е корисна од неколку причини
-Не се применува доколку нашиот податочен сет е веќе балансиран(содржи примероци кои припаѓаат подеднакво на сите класи)
Во овој случај обичната Accuracy ни е доволна.
-Го зима во предвид просекот на точноста за секоја класа, меѓутоа ова не ја вклучува важноста на разни класи во конкретни проблеми
------------------------------------------------------------------------------------------------------------------------

1. Модел на линеарна регресија
Моделот на линеарна регресија вообичаено се користи за нумерички тип на променливи(континуирани).
Овој модел можеме да го примениме доколку извршиме анализа на распределбата на податоците и видиме
дека постои корелација, односно некаква линеарна зависност помеѓу променливата која ја предвидуваме Y
и независните променливи X. Целта на овој модел е да се предвиди зависноста помеѓу зависната променлива врз 
основа на познатите независни променливи, односно нивното влијание.
Овој модел користи равенка на права линија за да ги предвиди вредностите
 Y = β0 + β1*x +  ε
Пример можеме да го искористиме доколку сакаме да видиме како плоштината на една куќа 
ќе влијае врз нејзината цена, во овој случај независни променливи X ќе бидат плоштините,
од друга страна зависна променлива која ќе ја предвидуваме ќе биде цената.

2. КNN модел за класификација
Овој е еден од најпопуларните модели за класификација, каде се користи за 2та типа на променливи,
но вообичаено се користи доколку зависната променлива Y која ја превидуваме е од категориски тип.
Предвидува излез за нов примерок врз основа на неговите најблиски соседи во податочниот сет.
Тој функционира на начин што го мери растојанието од новата точка до сите точки во тренинг податоците.
(бараме менхетенско растојание) Ги наоѓа најблиските к-соседи до новата точка , бидејќи станува збор
за класификација ја избира најчестата класа од тие к-точки, но доколку е регресија, го зима просекот
за нивните вредности.

3.Модел на логистичка регресија
Логистичката регресија е статистички модел кој се користи за класификаицја, односно кога
зависната променливплати кредит врз база на неговата кредитна историја итн. 
Таа користи логистичка функција која претвора линеарна комбинација на независни променливи во 
вредност помеѓу 0 и 1. Ако резултатот е поголем од 0.5 вообичаено се класифицира како 1 (позитивен случај)
, ако е помал од 0.5 се клаисифицира како 0 (негативен случај)
Сепак, недостаток на овој модел е тоа што е чувствителен на аутлаер.

4.Модел на полиномијална регресија
Полиномијалната регресија е еден вид проширување на линеарната регресија, со таа разлика што
се јавува доколку постои нелинеарна зависност помеѓу влезот и излезот. Наместо тоа што кај
линеарната регресија се користеше линеарна комбинација на независните променливи , да ги најдеме
B0, B1.. тука имаме и хиперпараметар(метаподаток) кој ни дава можност да одбереме параметар(полином)
кој што ќе ни го оформи моделот. Пример хиперпараметар кај КНН претставува бројот на соседи,
тука ни е x на некој степен (X^n)
Пример во еден координатен систем имаме 6 точки и ние можеме да креираме полиномна функција
која ќе мине низ сите 6 точки, односно да креираме модел кој ќе ги превиди со 100 % точност,но моделот 
нема да може добро да предвидува нови непознати примероци , со ова грешките кај train множеството
ќе се намалата, но ќе се зголемат кај test множеството, односно ова може да доведе до нов проблем
познат како overfitting (кога доведувањето на подобрување
на перформансите на моделот на тренинг множеството води кон влошување на перформансите на моделот 
на тест множеството.

5. Decisiton Tree модел 
Моделот на decision tree се состои од 3 дела :
1) коренот на дрвото(root) - ги содржи сите податоци
2) внатрешни јазли(internal nodes) - се создаваат врз основа на прашања или услови засновани на некој feature на податоците
3) листовите - конечна одлука или предвидување
како функционира моделот?
1) поделба на податоците (splitting) 
дрвото одлучува како ќе ги подели податоците врз основа на некоја нивна карактеристика(feature) , тука се користат разни метрики како gini index(за колку е чист одреден јазол), ентропија, mean squered error(за регресија, мери разлика меѓу предвидените вредности и вистинските вредности )
2) рекурзија - се повторува процесот се додека не се исполни услов за стоп(пр. достигната е максимална длабочина на дрво, нема веќе податоци за делење, класите се чисти)
3) одлука - секој лист претставува крајна одлука, за класификација најчесто е некоја класа, за регреија е некоја просечна вредност
- се користи и за категориски и за континуирани променливи
- не бара претходна нормализација на податоците
Џини индекс е мерка која се користи кај decision trees за да одреди колкава е хомогеноста(чистотата) во еден јазол , помага да се одбере кој feauture е  најдобар за да се избере при поделба на податоците
- колку е помал џини индексот толку е почист јазолот(node); 
чист јазол - сите податоци припаѓаат на една класа (џини = 0)
нечист јазол - податоците се мешавина од повеќе класи

____________
Bootstraping е статистички метод кој се користи за проценка на распределбата на примероците и за добивање на доверливи интервали или статистички проценки, користејќи повторно примероци од оригиналните податоци. Тоа вклучува случајно земање примероци со замена од оригиналниот податочен сет (т.е. истиот податок може да се појави повеќе пати во новиот примерок). Овој метод е корисен кога не се има претходна претпоставка за обликот на распределбата или кога работиме со мали примероци.

